---
id: 2091
title: 'Awatar miga w PJM'
date: '2021-02-11T18:34:09+01:00'
layout: post
guid: 'http://informaton.blog/?p=2091'
permalink: /2021/02/11/awatar-miga-w-pjm/
publicize_linkedin_url:
    - ''
timeline_notification:
    - '1613064850'
publicize_twitter_user:
    - jaczad
categories:
    - artykuły
tags:
    - animacja
    - badania
    - gry
    - 'język migowy'
    - PJM
    - 'sztuczna inteligencja'
    - 'tłumaczenia migowe'
---

Przeczytałem dzisiaj raport z badania nad awatarem, który ma migać, czyli przekazywać informacje w języku migowym. Tu jest [strona projektu](http://www.migowisko.pl/sztukamigania/), gdzie można znaleźć trochę informacji, próbki prezentacji sztucznych tłumaczy i raport z badań. Pomysł nie jest nowy, chociaż tego rodzaju projekty zazwyczaj kończą się porażką.

Ludzie, którzy nie znają specyfiki polskiego języka migowego (PJM) mogą pytać, na czym polega problem? Przecież wystarczy dla każdego słowa zaprogramować niezbędne gesty i już. To jednak wcale nie jest takie proste, bo PJM nie jest językiem polskim pokazywanym na migi. W zasadzie nie ma nic wspólnego z językiem polskim. Ma inną gramatykę, składnię i wszystko to, co może różnić języki między sobą. Do przekazu wykorzystuje się zaś nie tylko ręce – jak sądzi wiele osób – lecz także twarz (mimika), usta, oczy i resztę ciała. Można zatem przyjąć, że najpierw trzeba dokonać tłumaczenia z języka polskiego na jakąś formę pośrednią, która dopiero podlegać będzie przekazaniu do awatara.

Ludzie znający się na PJM kręcą głowami, że to nie zadziała. Język migowy nie jest jeszcze porządnie skodyfikowany, a tłumaczenie z polskiego jest trudne. Awatary zaś są nienaturalne w ruchach, co zresztą potwierdza raport z badania. Sami respondenci zwracali zaś uwagę na fakt, że nie da się z awatarem nawiązać kontaktu, wejść w interakcję, a zatem choćby dopytać lub upewnić się.

Ja zaś pomyślałem o ewolucji, jaką przeszły syntezatory mowy. Kiedy zacząłem ich używać około 25 lat temu, nikt nie chciał być ze mną w tym samym pomieszczeniu. Z głośników dochodziły jakieś skrzeczące piski, z których tylko ja coś mogłem zrozumieć. Żaden ówczesny syntezator mowy nawet nie próbował brzmieć jak człowiek. Teraz sytuacja jest zupełnie inna. Sztuczna mowa jest używana na dworcach kolejowych do zapowiedzi, w systemach call center i w czytnikach książek elektronicznych. Często ludzie nawet nie wiedzą, że słuchają sztucznej mowy. Może więc ten projekt jest realny.

Wyobrażam sobie, że to trochę tak, jak z syntezatorem mowy. Mamy analizator, który rozkłada tekst podany w strumieniu na elementy zrozumiałe dla końcówki syntezującej. Ten konwerter dla języka polskiego zrobić było łatwo, czego nie da się powiedzieć o innych językach. Za to bardzo trudne było zbudowanie końcówki syntezującej brzmiącej naturalnie. To była droga trwająca kilkadziesiąt lat.

W przypadku migającego awatara oba elementy są trudne. Strumień tekstu w języku polskim trzeba **przetłumaczyć**, a nie dokonać prostej konwersji. Jak takie tłumaczenia wyglądają, można sprawdzić w tłumaczu Google, który i tak działa już niemal doskonale. Jednak język migowy dopiero raczkuje i w zasadzie tylko ludzie potrafią sprawnie tłumaczyć.

Zrobienie dobrze i naturalnie wyglądającego awatara też jest trudne, chociaż paradoksalnie chyba łatwiejsze, niż tłumaczenie z polskiego na PJM. A to dzięki grom wideo, gdzie od wielu lat dopracowywane są animacje postaci, by wyglądały jak najnaturalniej. I z tą działką wiąże się też zagrożenie, które dostrzegłem w tym projekcie. A jest nim zjawisko „doliny niesamowitości”.

W [Wikipedii zjawisko opisano zostało w następujący sposób](https://pl.wikipedia.org/wiki/Dolina_niesamowito%C5%9Bci):

> Dolina niesamowitości – termin stosowany w hipotezie naukowej, zgodnie z którą robot, rysunek lub animacja komputerowa wyglądający bądź funkcjonujący podobnie (lecz nie identycznie) jak człowiek, wywołuje u obserwatorów nieprzyjemne odczucia, a nawet odrazę.

Już 50 lat temu japoński inżynier Masahiro Mori zauważył i przeprowadził badania potwierdzające, że ludzie boją się, odczuwają niechęć do postaci, które są bardzo podobne do człowieka, ale jednak da się zauważyć różnice. Zjawisko wciąż ma status hipotezy, ale były już badania potwierdzające ją. Dlatego właśnie postaci z gier wideo wcale nie są tak naturalne, jak mogłyby być i na co pozwalałaby dzisiejsza technologia. Bo byłyby bardzo podobne do ludzi, ale nie do końca. Może być zaś tak, że awatary Agnieszka i Michał też wylądują w dolinie niesamowitości. Im bardziej programiści będą ich upodabniać do ludzi, tym mniej chętnie będą z nich korzystać głusi. Ciekawe, czy badacze brali to pod uwagę, bo na stronie nie znalazłem o tym ani słowa.